{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":175,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n#import keras\n\nX_train = pd.read_csv('../input/digit-recognizer/train.csv')\nX_test = pd.read_csv('../input/digit-recognizer/test.csv')\nX_train.head()","execution_count":176,"outputs":[{"output_type":"execute_result","execution_count":176,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Determining the size of input X\nn_x, n_xcol = X_train.shape[0], X_train.shape[1]\nprint(n_x, n_xcol)","execution_count":177,"outputs":[{"output_type":"stream","text":"42000 785\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting raw data into labels and useful data\n\ny_train = np.array(X_train['label'])\nX_train = X_train.drop(['label'], axis = 1)\nX_train.columns","execution_count":178,"outputs":[{"output_type":"execute_result","execution_count":178,"data":{"text/plain":"Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n       'pixel7', 'pixel8', 'pixel9',\n       ...\n       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n      dtype='object', length=784)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preprocess the data \n#Normalisation\n\nX_train = X_train / 255.","execution_count":179,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining Activation and Loss functions\n\ndef relu(Z):\n    Z = np.where(Z <= 0, 0, Z)\n    Z = np.where(Z > 0, 0, Z)\n    return Z\n\ndef cross_entropy(yhat, y):\n    l = -(np.sum(y * np.log(yhat)))\n    return l\n\ndef softmax(A):\n    f = (np.exp(A)/np.sum(np.exp(A)))\n    return f","execution_count":180,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''#Initialise parameters A, W, b for L layers\n\ndef initialise_parameters(X, layer_nos, hidden_layer_nos):\n    A_prev = np.array(X).T\n    parameters = {}\n    parameters['A0'] = A_prev\n    layer_caches = []\n    n_h = hidden_layer_nos\n    for i in range(layer_nos - 1):\n        #A_prev = np.array(X_train).T\n        n_x = A_prev.shape[0]\n        parameters['W' + str(i+1)] = np.random.randn(n_h, n_x) * 0.01\n        parameters['b' + str(i+1)] = np.zeros(n_h, 1)\n        parameters['Z' + str(i+1)] = np.dot(W, A_prev) + b\n        A_prev = relu(Z)\n        parameters['A' + str(i+1)] = A_prev\n        cache = (parameters['W' + str(i+1)], parameters['b' + str(i+1)], A_prev, parameters['Z' + str(i+1)])  #cache = (W, b, A_prev, Z)\n        layer_caches.append(cache)\n    \n    return caches, parameters'''","execution_count":181,"outputs":[{"output_type":"execute_result","execution_count":181,"data":{"text/plain":"\"#Initialise parameters A, W, b for L layers\\n\\ndef initialise_parameters(X, layer_nos, hidden_layer_nos):\\n    A_prev = np.array(X).T\\n    parameters = {}\\n    parameters['A0'] = A_prev\\n    layer_caches = []\\n    n_h = hidden_layer_nos\\n    for i in range(layer_nos - 1):\\n        #A_prev = np.array(X_train).T\\n        n_x = A_prev.shape[0]\\n        parameters['W' + str(i+1)] = np.random.randn(n_h, n_x) * 0.01\\n        parameters['b' + str(i+1)] = np.zeros(n_h, 1)\\n        parameters['Z' + str(i+1)] = np.dot(W, A_prev) + b\\n        A_prev = relu(Z)\\n        parameters['A' + str(i+1)] = A_prev\\n        cache = (parameters['W' + str(i+1)], parameters['b' + str(i+1)], A_prev, parameters['Z' + str(i+1)])  #cache = (W, b, A_prev, Z)\\n        layer_caches.append(cache)\\n    \\n    return caches, parameters\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialise parameters A, W, b for L layers\n\ndef initialise_parameters(X, layer_nos, hidden_layer_nos):\n    A_prev = np.array(X.T)\n    parameters = {}\n    #parameters['A0'] = A_prev\n    #layer_caches = []\n    n_h = hidden_layer_nos\n    for i in range(layer_nos-1):\n        #A_prev = np.array(X_train).T\n        n_x = A_prev.shape[0]\n        parameters['W' + str(i+1)] = np.random.randn(n_h, n_x) * 0.01\n        parameters['b' + str(i+1)] = np.zeros((n_h, 1))\n        '''parameters['Z' + str(i+1)] = np.dot(W, A_prev) + b\n        A_prev = relu(Z)\n        parameters['A' + str(i+1)] = A_prev'''\n        #cache = (parameters['W' + str(i+1)], parameters['b' + str(i+1)], A_prev, parameters['Z' + str(i+1)])  #cache = (W, b, A_prev, Z)\n        #layer_caches.append(cache)\n    parameters['W' + str(layer_nos)] = np.random.randn(1, n_h) * 0.01\n    parameters['b' + str(layer_nos)] = np.random.randn(1, 1)\n    \n    return parameters","execution_count":182,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set activation as relu for L-1 layers\n#Activation for L-th layer: softmax \n#Loss function: cross entropy\n'''\ndef activation_last_layer(num_layers, parameters):\n    L = num_layers\n    #linear_cache, parameters = initialise_parameters(X_train, L)\n    ZL = np.dot(parameters['W' + str(L)], parameters['A' + str(L-1)]) + parameters['b' + str(L)]\n    AL = softmax(ZL)\n    \n    activation_cache = (ZL, AL)\n    #caches = (linear_cache, activation_cache)\n    \n    return activation_cache'''","execution_count":183,"outputs":[{"output_type":"execute_result","execution_count":183,"data":{"text/plain":"\"\\ndef activation_last_layer(num_layers, parameters):\\n    L = num_layers\\n    #linear_cache, parameters = initialise_parameters(X_train, L)\\n    ZL = np.dot(parameters['W' + str(L)], parameters['A' + str(L-1)]) + parameters['b' + str(L)]\\n    AL = softmax(ZL)\\n    \\n    activation_cache = (ZL, AL)\\n    #caches = (linear_cache, activation_cache)\\n    \\n    return activation_cache\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_propagation(X, num_layers, parameters):\n    L = num_layers\n    #A_prev = np.array(X.T)\n    forward_parameters = {}\n    forward_parameters['A' + str(0)] = np.array(X.T)\n    for i in range(L - 1):\n        forward_parameters['Z' + str(i+1)] = np.dot(parameters['W' + str(i+1)], forward_parameters['A' + str(i)]) + parameters['b' + str(i+1)]\n        forward_parameters['A' + str(i+1)] = relu(forward_parameters['Z' + str(i+1)])\n        #forward_parameters['A' + str(i+1)] = A_prev\n    #linear_cache, parameters = initialise_parameters(X_train, L)\n    ZL = np.dot(parameters['W' + str(L)], forward_parameters['A' + str(L-1)]) + parameters['b' + str(L)]\n    AL = softmax(ZL)\n    forward_parameters['Z' + str(L)] = ZL\n    forward_parameters['A' + str(L)] = AL\n    #activation_cache = (ZL, AL)\n    #caches = (linear_cache, activation_cache)\n    \n    return forward_parameters","execution_count":184,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encode y into a probability distribution\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef oh_encode(y):\n    encoded_y = []\n    for i in y:\n        s = np.zeros(10)\n        s[i] = 1\n        encoded_y.append(s)\n    return np.array(encoded_y)","execution_count":185,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encode y_train\n\nlabelled_y = oh_encode(y_train)\nprint(labelled_y)","execution_count":186,"outputs":[{"output_type":"stream","text":"[[0. 1. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 1.]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_cost(labelled_y, forward_parameters):\n    cost = 0\n    y_hat = forward_parameters['A' + str(L)]\n    \n    cost += cross_entropy(y_hat, labelled_y)\n    \n    return cost, labelled_y","execution_count":187,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def backpropagation(labelled_y, forward_parameters, parameters, layer_nos):\n    back_parameters = {}\n    L = layer_nos\n    yhat = forward_parameters['A' + str(L)]\n    dZL= -(labelled_y - yhat)\n    dZ = dZL\n    dWL = np.dot(dZL, forward_parameters['A' + str(L-1)])\n    dbL = dZL\n    back_parameters['dZ' + str(L)]\n    back_parameters['dW' + str(L)]\n    back_parameters['db' + str(L)]\n    \n    for i in range(L-1, 0, -1):\n        dA = (parameters['W' + str(i+1)].T) * dZ\n        g_dr = []\n        for j in forward_parameters['Z' + str(i)]:\n            if (j > 0):\n                g_dr.append(1)\n            else:\n                g_dr.append(0)\n        dZ = np.dot(dA, np.array(g_dr))\n        dW = np.dot(dZ, forward_parameters['A' + str(i - 1)])\n        db = dZ\n        back_parameters['dZ' + str(i)]\n        back_parameters['dW' + str(i)]\n        back_parameters['db' + str(i)]\n    \n    return back_parameters","execution_count":188,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_parameters(parameters, back_parameters, layer_nos):\n    for i in range(L):\n        parameters['W' + str(i+1)] -= back_parameters['dW' + str(i+1)]\n        parameters['b' + str(i+1)] -= back_parameters['db' + str(i+1)]\n    return parameters","execution_count":189,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def complete_neural_network(X, distributed_y, layer_nos, hidden_layer_nos, Wb_parameters):\n    #WbAZ_cache, WbAZ_parameters = initialise_parameters(X, layer_nos, hidden_layer_nos)\n    forward_parameters = forward_propagation(X, layer_nos, Wb_parameters)\n    cost_loss = compute_cost(distributed_y, forward_parameters)\n    derivatives = backpropagation(distributed_y, forward_parameters, Wb_parameters, layer_nos)\n\n    return cost_loss, derivatives","execution_count":190,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_neural_network(X, distributed_y, layer_nos, hidden_layer_nos):\n    Wb_parameters = initialise_parameters(X, layer_nos, hidden_layer_nos)\n    for i in range(10):\n        loss, derivatives = complete_neural_network(X, distributed_y, layer_nos, hidden_layer_nos, Wb_parameters)\n        print('Loss after epoch ' + str(i + 1) + ': ' + str(loss))\n        Wb_parameters = update_parameters(Wb_parameters, derivatives, layer_nos)","execution_count":191,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_neural_network(X_train, labelled_y, 3, 5)","execution_count":192,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"shapes (5,784) and (5,42000) not aligned: 784 (dim 1) != 5 (dim 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-192-1aed34cc6848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelled_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-191-6e0d599a493e>\u001b[0m in \u001b[0;36mrun_neural_network\u001b[0;34m(X, distributed_y, layer_nos, hidden_layer_nos)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mWb_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialise_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_nos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_nos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_nos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_nos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWb_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss after epoch '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mWb_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWb_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_nos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-190-bc4cf06645bc>\u001b[0m in \u001b[0;36mcomplete_neural_network\u001b[0;34m(X, distributed_y, layer_nos, hidden_layer_nos, Wb_parameters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomplete_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_nos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_nos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWb_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#WbAZ_cache, WbAZ_parameters = initialise_parameters(X, layer_nos, hidden_layer_nos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mforward_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_nos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWb_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcost_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mderivatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWb_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_nos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-184-b096a2c838b5>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(X, num_layers, parameters)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mforward_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mforward_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mforward_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#forward_parameters['A' + str(i+1)] = A_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (5,784) and (5,42000) not aligned: 784 (dim 1) != 5 (dim 0)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}